{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name: JOEL RAJU\n",
        "\n",
        "Batch: R1\n",
        "\n",
        "Date: 20-02-2023\n",
        "\n",
        "Experiment Name: 2.2 Real world Image classification application with train, valid and test analysis\n",
        "\n",
        "Experiment Description: The experiment aims at designing a CNN classification model for classifyings Flowers using the generic model\n"
      ],
      "metadata": {
        "id": "JkeKuoWPD4ie"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87wH9eZZgQCA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4ZuR8aEzITx",
        "outputId": "bf06e420-b2c8-4a60-a8ac-3e13a88d4bff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4Y1s1e3y2kF"
      },
      "outputs": [],
      "source": [
        "# Step 1: Preprocess the dataset\n",
        "train_dir = '/content/drive/MyDrive/DNN/Traing'\n",
        "val_dir = '/content/drive/MyDrive/DNN/validation'\n",
        "test_dir = '/content/drive/MyDrive/DNN/Testing'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZDhIMFdkzf99"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh9wX7eqzj3V"
      },
      "outputs": [],
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "warJkHxKzny9",
        "outputId": "4aa033fa-5c94-4807-efd0-09763c1ec8d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3357 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "train_data = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAoc6VbYzo79",
        "outputId": "0416a80f-c49f-4471-8dca-e8186da0adfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 594 images belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "val_data = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDAwTfvwz3RN",
        "outputId": "f0b2469e-c2cd-4b62-a766-e5c38e535815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 366 images belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "test_data = val_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK2P5UBxz-x0"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define the model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(256, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFaEwoqfz_2E"
      },
      "outputs": [],
      "source": [
        "# Step 3: Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g9rvvuf0CMd",
        "outputId": "60fe25a3-59e9-4793-81b3-9266576c4f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "105/105 [==============================] - 1359s 13s/step - loss: 1.5168 - accuracy: 0.4033 - val_loss: 1.1189 - val_accuracy: 0.5269\n",
            "Epoch 2/10\n",
            "105/105 [==============================] - 546s 5s/step - loss: 1.1127 - accuracy: 0.5398 - val_loss: 0.9992 - val_accuracy: 0.6027\n",
            "Epoch 3/10\n",
            "105/105 [==============================] - 548s 5s/step - loss: 0.9631 - accuracy: 0.6205 - val_loss: 0.9418 - val_accuracy: 0.6465\n",
            "Epoch 4/10\n",
            "105/105 [==============================] - 546s 5s/step - loss: 0.8767 - accuracy: 0.6488 - val_loss: 0.8775 - val_accuracy: 0.6582\n",
            "Epoch 5/10\n",
            "105/105 [==============================] - 564s 5s/step - loss: 0.8038 - accuracy: 0.6994 - val_loss: 0.9366 - val_accuracy: 0.6599\n",
            "Epoch 6/10\n",
            "105/105 [==============================] - 561s 5s/step - loss: 0.7288 - accuracy: 0.7227 - val_loss: 0.8664 - val_accuracy: 0.6717\n",
            "Epoch 7/10\n",
            "105/105 [==============================] - 558s 5s/step - loss: 0.6488 - accuracy: 0.7551 - val_loss: 0.7930 - val_accuracy: 0.7071\n",
            "Epoch 8/10\n",
            "105/105 [==============================] - 560s 5s/step - loss: 0.6060 - accuracy: 0.7647 - val_loss: 0.7935 - val_accuracy: 0.7071\n",
            "Epoch 9/10\n",
            "105/105 [==============================] - 545s 5s/step - loss: 0.5592 - accuracy: 0.7861 - val_loss: 0.8314 - val_accuracy: 0.7054\n",
            "Epoch 10/10\n",
            "105/105 [==============================] - 533s 5s/step - loss: 0.5007 - accuracy: 0.8180 - val_loss: 0.9801 - val_accuracy: 0.6818\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Train the model\n",
        "history = model.fit(train_data,\n",
        "                    validation_data=val_data,\n",
        "                    epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnaRrGhf0MbU",
        "outputId": "8685f06f-756c-474d-9248-dc74f2d1fc2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105/105 [==============================] - 171s 2s/step - loss: 0.4036 - accuracy: 0.8549\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.40360522270202637, 0.8549299836158752]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Step 5: Evaluate the model\n",
        "#test_loss, test_acc = model.evaluate(test_data)\n",
        "#print('Test accuracy:', test_acc)\n",
        "model.evaluate(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSNHwEpQ0Om0"
      },
      "outputs": [],
      "source": [
        "# Step 6: Save the model\n",
        "model.save('flower_classification_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkJpTYB00SWs"
      },
      "outputs": [],
      "source": [
        "# Step 7: Load the model for making predictions on new images\n",
        "new_image = '/content/drive/MyDrive/DNN/OIP.jpg'\n",
        "new_image_data = tf.keras.preprocessing.image.load_img(new_image, target_size=(224, 224))\n",
        "new_image_data = tf.keras.preprocessing.image.img_to_array(new_image_data)\n",
        "new_image_data = np.expand_dims(new_image_data, axis=0)\n",
        "new_image_data /= 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R874ef7J01mz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3cb8f98-c599-4320-8ca1-420f1c74a6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 225ms/step\n",
            "Prediction: dandelion\n"
          ]
        }
      ],
      "source": [
        "model = tf.keras.models.load_model('flower_classification_model.h5')\n",
        "prediction = model.predict(new_image_data)\n",
        "class_index = np.argmax(prediction)\n",
        "classes = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n",
        "class_label = classes[class_index]\n",
        "print('Prediction:', class_label)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOYUGHa4urMD",
        "outputId": "54a7c7b3-2718-4f7c-8eae-51b12069dff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               22151424  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,245,957\n",
            "Trainable params: 22,245,957\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIZYSCkq1GhH"
      },
      "source": [
        "In this code, we use the Keras ImageDataGenerator class to preprocess the dataset and create generators for the training, validation, and test sets. We then define a simple convolutional neural network (CNN) architecture and compile the model with the Adam optimizer and categorical cross-entropy loss."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}